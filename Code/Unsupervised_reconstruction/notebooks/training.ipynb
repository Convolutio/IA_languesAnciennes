{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximisation-expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, chdir\n",
    "\n",
    "# set the current working directory to the repository's root, if required\n",
    "if getcwd().endswith('notebooks'):\n",
    "    chdir('./../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install tabulate\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}')\n",
    "\n",
    "def display_horizontaly_two_tables(df:pd.DataFrame,df2:pd.DataFrame, title1:str, title2:str):\n",
    "    df_md = df.to_markdown().split('\\n')\n",
    "    df2_md = df2.to_markdown().split('\\n')\n",
    "    title_line = title1 + \" \" * (len(df_md[0])-len(title1)) + \"\\t\" + title2\n",
    "    two_tabs = \"\\n\".join([title_line] + [df_md[i] + '\\t' + df2_md[i] for i in range(len(df_md))])\n",
    "    print(two_tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.getDataset import getCognatesSet, getIteration\n",
    "from data.vocab import computeInferenceData_Samples, computeInferenceData_Cognates, wordsToOneHots, vocabulary\n",
    "from models.types import ModernLanguages, MODERN_LANGUAGES, InferenceData_Cognates\n",
    "from Source.reconstructionModel import ReconstructionModel\n",
    "\n",
    "raw_cognates = getCognatesSet()\n",
    "cognates: dict[ModernLanguages, InferenceData_Cognates] = computeInferenceData_Cognates({lang: wordsToOneHots(raw_cognates[lang]) for lang in raw_cognates})\n",
    "raw_samples = getIteration(1)\n",
    "currentReconstructions = computeInferenceData_Samples(wordsToOneHots(raw_samples)) #TODO: simplify the data loading\n",
    "\n",
    "LSTM_INPUT_DIM = 50\n",
    "LSTM_HIDDEN_DIM = 50\n",
    "\n",
    "randomEditModel = ReconstructionModel(MODERN_LANGUAGES, vocabulary, LSTM_INPUT_DIM, LSTM_HIDDEN_DIM)\n",
    "\n",
    "TEST_LANGUAGE:ModernLanguages = \"french\"\n",
    "x_maxLength = currentReconstructions[0].size()[0] - 2\n",
    "y_maxLength = cognates[TEST_LANGUAGE][0].size()[0] - 2\n",
    "print('|y| max =', y_maxLength)\n",
    "print('|x| max =', x_maxLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward dynamic Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward dynamic Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_prob = randomEditModel.backward_dynProg(currentReconstructions, cognates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on $x :=$`\"absyrdʊ\"` and $y :=$`\"absˈyʁd\"` ($|x|=7$ and $|y|=7$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 20 # the index in the batch of the sample to be studied\n",
    "x_length, y_length = 7, 7\n",
    "\n",
    "backward_prob_dlt = targets_prob[TEST_LANGUAGE].dlt[:,:,IDX].cpu().numpy().squeeze(-1)\n",
    "backward_prob_end = targets_prob[TEST_LANGUAGE].end[:,:,IDX].cpu().numpy().squeeze(-1)\n",
    "backward_prob_sub = targets_prob[TEST_LANGUAGE].sub[:,:,IDX].cpu().numpy().squeeze(-1)\n",
    "backward_prob_ins = targets_prob[TEST_LANGUAGE].ins[:,:,IDX].cpu().numpy().squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display of cached probabilities for the substitution and the deletion operations\n",
    "\n",
    "Notice that the logarithmic probabilities that have not to be defined for these operations are automatically set to $-\\infty{}$ thanks to the recurrence mathematical relations of the backward dynamic program. So do the undefined probabilities in padding positions, thanks to the neutrality of edit model's cached inference probabilities (which equal $0$ in the log space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(backward_prob_sub[:x_length+2, :y_length+2])\n",
    "df2 = pd.DataFrame(backward_prob_dlt[:x_length+2, :y_length+2])\n",
    "\n",
    "display_horizontaly_two_tables(df, df2, \"Subsitution Operation\", \"Deletion Operation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target probs transformation for the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from Source.utils import dl_to_ld\n",
    "from models.types import Operations\n",
    "for lang in targets_prob.keys():\n",
    "    targets_prob[lang] = targets_prob[lang].toTargetsProbs()\n",
    "targets_prob: list[dict[ModernLanguages, dict[Operations, Tensor]]] = dl_to_ld(targets_prob) #type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderedTargets = targets_prob[IDX][TEST_LANGUAGE]\n",
    "df_renderedSub = pd.DataFrame(renderedTargets['sub'].squeeze(-1).squeeze(-1)[:x_length+2, :y_length+2])\n",
    "df2_renderedDlt = pd.DataFrame(renderedTargets['dlt'].squeeze(-1).squeeze(-1)[:x_length+2, :y_length+2])\n",
    "display_horizontaly_two_tables(df_renderedSub, df2_renderedDlt, \"Subsitution Operation\", \"Deletion Operation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.reconstruction_datasets import trainingDataLoader\n",
    "\n",
    "MINI_BATCH_SIZE = 30\n",
    "NUM_WORKERS = 1\n",
    "dl = trainingDataLoader(raw_samples, dl_to_ld(raw_cognates), targets_prob, MINI_BATCH_SIZE, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS, LEARNING_RATE = 5, 0.01\n",
    "randomEditModel.train_models(dl, EPOCHS, LEARNING_RATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
