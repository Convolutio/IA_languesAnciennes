{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, chdir\n",
    "\n",
    "if getcwd().endswith('notebooks'):\n",
    "    chdir('..')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the cognates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the generation, the cognates already need to be transformed into the ByteTensor format. Each ByteTensor in the list of dictionnaries has the elementary shape $\\left( |y_{c, l}|\\right)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor, Tensor, uint8\n",
    "from data.vocab import vocabulary\n",
    "from data.getDataset import getCognatesSet\n",
    "from source.utils import dl_to_ld\n",
    "from models.types import ModernLanguages\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "cognates: list[dict[ModernLanguages, Tensor]] = [{lang:tensor(data=vocabulary(list(d[lang])), dtype=uint8, device=device) for lang in d} for d in dl_to_ld(getCognatesSet())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Choose one of the two proposed generation methods for the test by setting the constant below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_WITH_ALGORITHM = False\n",
    "samples: list[Tensor] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_NUMBER_PER_COGNATE_GROUP = 40000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Random prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.createSamples import createSamplesBatch\n",
    "if not GENERATE_WITH_ALGORITHM:\n",
    "    samples = createSamplesBatch(len(cognates), SAMPLES_NUMBER_PER_COGNATE_GROUP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. With the generation algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the first Bouchard-Côté model's iteration for the reconstructions from which the generation will be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.getDataset import getIteration\n",
    "from source.generateProposals import generateProposalsFromCurrentReconstructions\n",
    "\n",
    "if GENERATE_WITH_ALGORITHM:\n",
    "    currentReconstructions: list[Tensor] = [tensor(data=vocabulary(list(word)), dtype=uint8, device=device) for word in getIteration(1)]\n",
    "    samples = generateProposalsFromCurrentReconstructions(currentReconstructions, cognates, SAMPLES_NUMBER_PER_COGNATE_GROUP)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.reconstructionModel import ReconstructionModel\n",
    "from models.types import MODERN_LANGUAGES\n",
    "\n",
    "LSTM_INPUT_DIM = 50\n",
    "LSTM_HIDDEN_DIM = 50\n",
    "\n",
    "randomEditModel = ReconstructionModel(MODERN_LANGUAGES, vocabulary, LSTM_INPUT_DIM, LSTM_HIDDEN_DIM).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Language Model with neutral probability for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\screamnox\\Desktop\\School\\Projet CPBx\\Github\\IA_languesAnciennes\\Code\\Unsupervised_reconstruction\\.env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.types import InferenceData_Samples\n",
    "from lm.PriorLM import PriorLM\n",
    "from torch import zeros, float32\n",
    "\n",
    "class LM(PriorLM):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def inference(self, reconstructions: InferenceData_Samples):\n",
    "        return zeros(size=reconstructions[1].size(), dtype=float32, device=device)\n",
    "    \n",
    "random_lm = LM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute unnormalized probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of roughly $\\frac{B \\cdot C}{b \\cdot c}$ mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.reconstruction_datasets import samplingDataLoader\n",
    "\n",
    "MINI_BATCH_SHAPE = (30, 100)\n",
    "dataloader = samplingDataLoader(samples, cognates, MINI_BATCH_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unnormalized probabilities are computed from by running the inference in the prior language model and the forward dynamic program for each edit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Example:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probs tensor shape from french's edit model: torch.Size([30, 100])\n",
      "Probs tensor shape from spanish's edit model: torch.Size([30, 100])\n",
      "Probs tensor shape from italian's edit model: torch.Size([30, 100])\n",
      "Probs tensor shape from portuguese's edit model: torch.Size([30, 100])\n",
      "Probs tensor shape from romanian's edit model: torch.Size([30, 100])\n",
      "Probs tensor shape from prior edit model: torch.Size([30, 100])\n",
      "Unnormalized probs tensor shape: torch.Size([30, 100])\n"
     ]
    }
   ],
   "source": [
    "elt = next(iter(dataloader))\n",
    "edit_models_results = randomEditModel.forward_dynProg(*elt[0])\n",
    "prior_lm_results = random_lm.inference(elt[0][0])\n",
    "for lang in edit_models_results:\n",
    "    print(f'Probs tensor shape from {lang}\\'s edit model: {edit_models_results[lang].size()}')\n",
    "print(f'Probs tensor shape from prior edit model:', prior_lm_results.size())\n",
    "\n",
    "unnormalized_probs = prior_lm_results\n",
    "for lang in edit_models_results:\n",
    "    unnormalized_probs += edit_models_results[lang]\n",
    "print('Unnormalized probs tensor shape:', unnormalized_probs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Complete iteration:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m----> 2\u001b[0m     __edit_models_results \u001b[39m=\u001b[39m randomEditModel\u001b[39m.\u001b[39;49mforward_dynProg(\u001b[39m*\u001b[39;49mdata[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      3\u001b[0m     __prior_lm_results \u001b[39m=\u001b[39m random_lm\u001b[39m.\u001b[39minference(data[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m     __results \u001b[39m=\u001b[39m __prior_lm_results\n",
      "File \u001b[1;32mc:\\Users\\screamnox\\Desktop\\School\\Projet CPBx\\Github\\IA_languesAnciennes\\Code\\Unsupervised_reconstruction\\source\\reconstructionModel.py:176\u001b[0m, in \u001b[0;36mReconstructionModel.forward_dynProg\u001b[1;34m(self, samples, cognates)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[39mfor\u001b[39;00m language \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanguages:\n\u001b[0;32m    175\u001b[0m         model: EditModel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__editModels[language]  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m         mutation_prob \u001b[39m=\u001b[39m compute_mutation_prob(\n\u001b[0;32m    177\u001b[0m             model, sources, cognates[language])\n\u001b[0;32m    178\u001b[0m         probs[language] \u001b[39m=\u001b[39m mutation_prob \u001b[39m#type: ignore\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m probs\n",
      "File \u001b[1;32mc:\\Users\\screamnox\\Desktop\\School\\Projet CPBx\\Github\\IA_languesAnciennes\\Code\\Unsupervised_reconstruction\\source\\dynamicPrograms.py:29\u001b[0m, in \u001b[0;36mcompute_mutation_prob\u001b[1;34m(model, sources_, targets_, return_posteriors)\u001b[0m\n\u001b[0;32m     26\u001b[0m max_source_sequenceLength \u001b[39m=\u001b[39m max_rawSource_sequenceLength \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m     27\u001b[0m max_target_sequenceLength \u001b[39m=\u001b[39m max_rawTarget_sequenceLength \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m---> 29\u001b[0m model\u001b[39m.\u001b[39;49mcache_probs(sources_, targets_)\n\u001b[0;32m     31\u001b[0m \u001b[39m# apparently faster in numpy for indexing but \u001b[39;00m\n\u001b[0;32m     33\u001b[0m f_sub \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull((max_source_sequenceLength, max_target_sequenceLength, \u001b[39m*\u001b[39mbatch_shape), fill_value\u001b[39m=\u001b[39mBIG_NEG, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\screamnox\\Desktop\\School\\Projet CPBx\\Github\\IA_languesAnciennes\\Code\\Unsupervised_reconstruction\\source\\editModel.py:182\u001b[0m, in \u001b[0;36mEditModel.cache_probs\u001b[1;34m(self, sources, targets)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat((\n\u001b[0;32m    177\u001b[0m         torch\u001b[39m.\u001b[39mcat((t, torch\u001b[39m.\u001b[39mzeros((padding_x, \u001b[39m*\u001b[39mt\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m:]), device\u001b[39m=\u001b[39mdevice)), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), \n\u001b[0;32m    178\u001b[0m         torch\u001b[39m.\u001b[39mzeros((t\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, padding_y, \u001b[39m*\u001b[39mt\u001b[39m.\u001b[39msize()[\u001b[39m2\u001b[39m:]), device\u001b[39m=\u001b[39mdevice)), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    179\u001b[0m     )\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    181\u001b[0m \u001b[39m# dim = (|x|+2, |y|+2, c, b)\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__cachedProbs \u001b[39m=\u001b[39m {op:lengthen(t, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m (op, t) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_and_select(sources, targets)\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[1;32mc:\\Users\\screamnox\\Desktop\\School\\Projet CPBx\\Github\\IA_languesAnciennes\\Code\\Unsupervised_reconstruction\\source\\editModel.py:182\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat((\n\u001b[0;32m    177\u001b[0m         torch\u001b[39m.\u001b[39mcat((t, torch\u001b[39m.\u001b[39mzeros((padding_x, \u001b[39m*\u001b[39mt\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m:]), device\u001b[39m=\u001b[39mdevice)), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), \n\u001b[0;32m    178\u001b[0m         torch\u001b[39m.\u001b[39mzeros((t\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, padding_y, \u001b[39m*\u001b[39mt\u001b[39m.\u001b[39msize()[\u001b[39m2\u001b[39m:]), device\u001b[39m=\u001b[39mdevice)), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    179\u001b[0m     )\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    181\u001b[0m \u001b[39m# dim = (|x|+2, |y|+2, c, b)\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__cachedProbs \u001b[39m=\u001b[39m {op:lengthen(t, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m (op, t) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_and_select(sources, targets)\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[1;32mc:\\Users\\screamnox\\Desktop\\School\\Projet CPBx\\Github\\IA_languesAnciennes\\Code\\Unsupervised_reconstruction\\source\\editModel.py:182\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat((\n\u001b[0;32m    177\u001b[0m         torch\u001b[39m.\u001b[39mcat((t, torch\u001b[39m.\u001b[39mzeros((padding_x, \u001b[39m*\u001b[39mt\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m:]), device\u001b[39m=\u001b[39mdevice)), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), \n\u001b[0;32m    178\u001b[0m         torch\u001b[39m.\u001b[39mzeros((t\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, padding_y, \u001b[39m*\u001b[39mt\u001b[39m.\u001b[39msize()[\u001b[39m2\u001b[39m:]), device\u001b[39m=\u001b[39mdevice)), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    179\u001b[0m     )\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    181\u001b[0m \u001b[39m# dim = (|x|+2, |y|+2, c, b)\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__cachedProbs \u001b[39m=\u001b[39m {op:lengthen(t, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m (op, t) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_and_select(sources, targets)\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\screamnox\\Desktop\\School\\Projet CPBx\\Github\\IA_languesAnciennes\\Code\\Unsupervised_reconstruction\\.env\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\screamnox\\Desktop\\School\\Projet CPBx\\Github\\IA_languesAnciennes\\Code\\Unsupervised_reconstruction\\.env\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    __edit_models_results = randomEditModel.forward_dynProg(*data[0])\n",
    "    __prior_lm_results = random_lm.inference(data[0][0])\n",
    "    __results = __prior_lm_results\n",
    "    for lang in __edit_models_results:\n",
    "        __results += __edit_models_results[lang]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
