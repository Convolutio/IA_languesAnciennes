{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Language Models\n",
    "\n",
    "*Computing of $p(x)$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this before continuing so that the imports work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir, getcwd\n",
    "\n",
    "if getcwd().endswith('notebooks'):\n",
    "    chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|IPA| = 57\n",
      ") 57\n",
      "( 58\n",
      "- 59\n"
     ]
    }
   ],
   "source": [
    "from data.vocab import vocabulary\n",
    "from models.models import EOS_TOKEN, SOS_TOKEN, PADDING_TOKEN\n",
    "\n",
    "print('|IPA| =', len(vocabulary)-3) # '-3' because `vocabulary` contains the IPA characters plus the special tokens listed below\n",
    "for token in (EOS_TOKEN, SOS_TOKEN, PADDING_TOKEN):\n",
    "    print(token, vocabulary[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zɣmɒusʲˈːʔɨokpeaβøbfɡʒyɲɾˌɛdɹwxnlrœɐʁvʌʊŋʝʰʎjhðʃɪɔ̃əɑiθtɥ\n",
      "kʰrˈɔnɪkɔn kˈɔdɛks aʊɡɪˈɛnsɪs ˈannʊs aʊɡˈʊstʊs kˈaɪsar ɛks kwˈɔ ˈaʊtɛm aɪɡˈyptʊs ɪn prɔwˈɪŋkɪa rˈɛdɪ\n",
      "ɛt sʊbˈɪkɪɔ bˈɛda rˈɛdɛɔ ɡˈɔtʰɪs ab ab spˈɛs dɪɔnˈysɪʔɪ alpʰˈɛɪdɛ fˈɪlɪʊs ab fˈɪlɪʊs ˈɪpsɛ ˈɪɔr ɛkːl\n",
      "sˈʊpːlɛks bɛllˈɪkɔsʊs kʊm ˈɔswɪ ˈal rˈɛks fˈɔrtɪs pˈɛrsɛkwɔr sˈʊmɔ nˈɔbɪlɪs mˈɔrs sˈɪkʊt trˈʊkɪdɔ pɛ\n",
      "ɡʊntʰˈarɪʊs sʊm ˈɛkskʊsɔ ɡˈallɪa lɔŋɡɔbˈardɔrʊm hɪɛrɔsɔlˈymam sˈʊkːɛdɔ kˈɔɪlɪs ˈɔmnɪs mˈaŋnʊs kˌɪrka\n"
     ]
    }
   ],
   "source": [
    "from data.getDataset import getLMTrainingSet\n",
    "\n",
    "# Following 'Article Scientifique' there are three db of different sizes.\n",
    "DB_SIZE = [20_000, 10_000, 5_000]\n",
    "\n",
    "# Generate the three db of different sizes.\n",
    "tokens_20k, tokens_10k, tokens_5k = getLMTrainingSet(DB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x13252bb2b80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data.backward_compatibility import worker_init_fn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.datasets import CC100\n",
    "\n",
    "dp = CC100(root='./out/cache', language_code='la')\n",
    "DataLoader(dp, shuffle=True, num_workers=4, worker_init_fn=worker_init_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58,\n",
      "         58, 58, 58, 58, 58, 58],\n",
      "        [32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  1,  1,  1, 55,  1,  1,  1,  1,  1,  1,  1, 43, 43,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1],\n",
      "        [ 0,  0,  2, 32,  7,  9,  9,  9, 11, 17, 17, 30, 15, 15, 15, 15, 15, 15,\n",
      "         15, 15, 15, 30, 30, 21],\n",
      "        [11,  2,  6, 14, 32,  0,  0, 43, 36,  9, 10, 14, 37, 32, 37, 30, 16, 16,\n",
      "         16, 16, 21, 11, 11, 15],\n",
      "        [43, 32,  8,  0,  8, 56, 16, 56, 33,  6,  6, 16, 11, 11, 11, 14,  6,  6,\n",
      "         14, 14, 14,  2,  2, 43],\n",
      "        [57, 15,  0, 56, 16, 27,  6, 27,  0,  3, 11,  6, 16, 15, 16,  1, 11, 11,\n",
      "          0,  0,  2,  0,  0, 57],\n",
      "        [59,  0, 14, 15, 43, 30, 18, 30, 15, 57,  0, 18, 57,  0, 43, 14, 32, 37,\n",
      "          8,  8, 43, 14, 11, 59],\n",
      "        [59, 57, 57, 30, 57, 57, 43, 57, 30, 59,  1, 43, 59, 57, 57,  3, 11, 11,\n",
      "         15, 15, 57, 57, 15, 59],\n",
      "        [59, 59, 59, 57, 59, 59, 57, 59, 57, 59,  9, 57, 59, 59, 59, 57, 16, 15,\n",
      "         30, 30, 59, 59,  0, 59],\n",
      "        [59, 59, 59, 59, 59, 59, 59, 59, 59, 59,  9, 59, 59, 59, 59, 59, 57,  0,\n",
      "         30, 57, 59, 59, 57, 59],\n",
      "        [59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 57, 59, 59, 59, 59, 59, 59, 57,\n",
      "         57, 59, 59, 59, 59, 59]], device='cuda:0', dtype=torch.int32), tensor([ 5,  7,  7,  8,  7,  7,  8,  7,  8,  6, 10,  8,  6,  7,  7,  8,  9, 10,\n",
      "        10,  9,  7,  7,  9,  5]), 10)\n"
     ]
    }
   ],
   "source": [
    "from data.getDataset import getIteration\n",
    "from data.vocab import computeInferenceData\n",
    "\n",
    "sources = computeInferenceData(getIteration(3)[:, :24], vocabulary)\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word for test: (absyrdʊ)---\n",
      "\n",
      "word IntTensor: tensor([58,  0,  1, 15, 21, 14,  2, 43, 57, 59, 59, 59], device='cuda:0',\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "from data.vocab import oneHotsToWords\n",
    "\n",
    "testIndexInBatch = 20\n",
    "word = oneHotsToWords(sources[0][:,testIndexInBatch:testIndexInBatch+1], False, vocabulary)[0]\n",
    "print(f\"word for test: {word}\\n\")\n",
    "print(f\"word IntTensor: {sources[0][:, testIndexInBatch]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\screamnox\\Desktop\\School\\Projet CPBx\\Github\\IA_languesAnciennes\\Code\\Unsupervised_reconstruction\\.env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda import is_available\n",
    "from lm.PriorLM import CharLM\n",
    "\n",
    "device = 'cuda' if is_available() else 'cpu'\n",
    "\n",
    "# Init the character level LSTM language model \n",
    "LSTM_lm = CharLM(embedding_size=1024, hidden_size=100, num_layers=2, dropout_rate=0.1, vocab=vocabulary).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***`TODO`***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p('(absyrdʊ)---') = -32.498138427734375\n"
     ]
    }
   ],
   "source": [
    "probs = LSTM_lm.inference(sources)\n",
    "print(f\"p('{word}') =\", probs[testIndexInBatch].item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $n$-gram LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm.PriorLM import NGramLM\n",
    "\n",
    "bigram_20k = NGramLM(n=2, vocab=vocabulary)\n",
    "bigram_10k = NGramLM(n=2, vocab=vocabulary)\n",
    "bigram_5k = NGramLM(n=2, vocab=vocabulary)\n",
    "\n",
    "trigram_20k = NGramLM(n=3, vocab=vocabulary)\n",
    "trigram_10k = NGramLM(n=3, vocab=vocabulary)\n",
    "trigram_5k = NGramLM(n=3, vocab=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[58,  0],\n",
      "         [58,  6]],\n",
      "\n",
      "        [[ 0,  1],\n",
      "         [ 6,  4]],\n",
      "\n",
      "        [[ 1, 15],\n",
      "         [ 4,  6]],\n",
      "\n",
      "        [[15, 21],\n",
      "         [ 6,  8]],\n",
      "\n",
      "        [[21, 14],\n",
      "         [ 8,  0]],\n",
      "\n",
      "        [[14,  2],\n",
      "         [ 0, 14]],\n",
      "\n",
      "        [[ 2, 43],\n",
      "         [14,  3]],\n",
      "\n",
      "        [[43, 57],\n",
      "         [ 3, 57]]], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "sentence_test = \"absyrdʊ ifikare\"\n",
    "batch = bigram_20k.batch_ngram(sentence_test)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         ...,\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
       "\n",
       "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         ...,\n",
       "         [   -inf,    -inf,    -inf,  ...,  0.0000,    -inf,    -inf],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
       "\n",
       "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         ...,\n",
       "         [   -inf,    -inf,    -inf,  ...,  0.0000,    -inf,    -inf],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         ...,\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,  0.0000],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,  0.0000]],\n",
       "\n",
       "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf],\n",
       "         ...,\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [   -inf, -3.8317, -3.0307,  ...,    -inf,    -inf,    -inf],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
       "\n",
       "        [[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         ...,\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [   -inf,    -inf,    -inf,  ...,    -inf,    -inf,  0.0000]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Torch MP\n",
    "bigram_20k.train(tokens_20k)\n",
    "bigram_10k.train(tokens_10k)\n",
    "bigram_5k.train(tokens_5k)\n",
    "\n",
    "trigram_20k.train(tokens_20k)\n",
    "trigram_10k.train(tokens_10k)\n",
    "trigram_5k.train(tokens_5k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bigram_20k\u001b[39m.\u001b[39;49minference(sources)\n\u001b[0;32m      2\u001b[0m bigram_10k\u001b[39m.\u001b[39minference(sources)\n\u001b[0;32m      3\u001b[0m bigram_5k\u001b[39m.\u001b[39minference(sources)\n",
      "File \u001b[1;32mc:\\Users\\screamnox\\Desktop\\School\\Projet CPBx\\Github\\IA_languesAnciennes\\Code\\Unsupervised_reconstruction\\lm\\PriorLM.py:140\u001b[0m, in \u001b[0;36mNGramLM.inference\u001b[1;34m(self, reconstructions)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minference\u001b[39m(\u001b[39mself\u001b[39m, reconstructions: InferenceData) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 140\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadDataToNgram(reconstructions[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m    141\u001b[0m     maxSequenceLength, batch_size, V \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mshape\n\u001b[0;32m    142\u001b[0m     \u001b[39m# begin with the neutral prob 1\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\screamnox\\Desktop\\School\\Projet CPBx\\Github\\IA_languesAnciennes\\Code\\Unsupervised_reconstruction\\lm\\PriorLM.py:124\u001b[0m, in \u001b[0;36mNGramLM.padDataToNgram\u001b[1;34m(self, reconstructions)\u001b[0m\n\u001b[0;32m    120\u001b[0m end_padding \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull(\n\u001b[0;32m    121\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, B), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab[PADDING_TOKEN], device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m    123\u001b[0m \u001b[39m# shape: (L+2*(self.n-2), B)\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m padded_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(\n\u001b[0;32m    125\u001b[0m     (first_padding, reconstructions[\u001b[39m0\u001b[39;49m], end_padding), dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    127\u001b[0m \u001b[39m# Indices of the first occurrence of 0 along the L dimension\u001b[39;00m\n\u001b[0;32m    128\u001b[0m indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(padded_tensor \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab[PADDING_TOKEN],\n\u001b[0;32m    129\u001b[0m                        dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    }
   ],
   "source": [
    "bigram_20k.inference(sources)\n",
    "bigram_10k.inference(sources)\n",
    "bigram_5k.inference(sources)\n",
    "\n",
    "trigram_20k.inference(sources)\n",
    "trigram_10k.inference(sources)\n",
    "trigram_5k.inference(sources)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
