{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, chdir\n",
    "\n",
    "if getcwd().endswith('notebooks'):\n",
    "    chdir('..')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the cognates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the generation, the cognates already need to be transformed into the ByteTensor format. Each ByteTensor in the list of dictionnaries has the elementary shape $\\left( |y_{c, l}|\\right)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor, Tensor, uint8\n",
    "from data.vocab import vocabulary\n",
    "from data.getDataset import getCognatesSet\n",
    "from Source.utils import dl_to_ld\n",
    "from models.types import ModernLanguages\n",
    "\n",
    "cognates: list[dict[ModernLanguages, Tensor]] = [{lang:tensor(data=vocabulary(list(d[lang])), dtype=uint8) for lang in d} for d in dl_to_ld(getCognatesSet())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Choose one of the two proposed generation methods for the test by setting the constant below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_WITH_ALGORITHM = False\n",
    "samples: list[Tensor] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_NUMBER_PER_COGNATE_GROUP = 40000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Random prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tests.createSamples import createSamplesBatch\n",
    "if not GENERATE_WITH_ALGORITHM:\n",
    "    samples = createSamplesBatch(len(cognates), SAMPLES_NUMBER_PER_COGNATE_GROUP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. With the generation algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the first Bouchard-Côté model's iteration for the reconstructions from which the generation will be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.getDataset import getIteration\n",
    "from Source.generateProposals import generateProposalsFromCurrentReconstructions\n",
    "\n",
    "if GENERATE_WITH_ALGORITHM:\n",
    "    currentReconstructions: list[Tensor] = [tensor(data=vocabulary(list(word)), dtype=uint8) for word in getIteration(1)]\n",
    "    samples = generateProposalsFromCurrentReconstructions(currentReconstructions, cognates, SAMPLES_NUMBER_PER_COGNATE_GROUP)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Source.reconstructionModel import ReconstructionModel\n",
    "from models.types import MODERN_LANGUAGES\n",
    "\n",
    "LSTM_INPUT_DIM = 50\n",
    "LSTM_HIDDEN_DIM = 50\n",
    "\n",
    "randomEditModel = ReconstructionModel(MODERN_LANGUAGES, vocabulary, LSTM_INPUT_DIM, LSTM_HIDDEN_DIM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Language Model with neutral probability for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.types import InferenceData_Samples\n",
    "from lm.PriorLM import PriorLM\n",
    "from torch import zeros, float32\n",
    "\n",
    "class LM(PriorLM):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def inference(self, reconstructions: InferenceData_Samples):\n",
    "        return zeros(size=reconstructions[1].size(), dtype=float32)\n",
    "    \n",
    "random_lm = LM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute unnormalized probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset of roughly $\\frac{B \\cdot C}{b \\cdot c}$ mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.reconstruction_datasets import samplingDataLoader\n",
    "\n",
    "MINI_BATCH_SHAPE = (30, 100)\n",
    "dataloader = samplingDataLoader(samples, cognates, MINI_BATCH_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unnormalized probabilities are computed from by running the inference in the prior language model and the forward dynamic program for each edit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Example:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probs tensor shape from french's edit model: torch.Size([30, 100])\n",
      "Probs tensor shape from spanish's edit model: torch.Size([30, 100])\n",
      "Probs tensor shape from italian's edit model: torch.Size([30, 100])\n",
      "Probs tensor shape from portuguese's edit model: torch.Size([30, 100])\n",
      "Probs tensor shape from romanian's edit model: torch.Size([30, 100])\n",
      "Probs tensor shape from prior edit model: torch.Size([30, 100])\n",
      "Unnormalized probs tensor shape: torch.Size([30, 100])\n"
     ]
    }
   ],
   "source": [
    "elt = next(iter(dataloader))\n",
    "edit_models_results = randomEditModel.forward_dynProg(*elt[0])\n",
    "prior_lm_results = random_lm.inference(elt[0][0])\n",
    "for lang in edit_models_results:\n",
    "    print(f'Probs tensor shape from {lang}\\'s edit model: {edit_models_results[lang].size()}')\n",
    "print(f'Probs tensor shape from prior edit model:', prior_lm_results.size())\n",
    "\n",
    "unnormalized_probs = prior_lm_results\n",
    "for lang in edit_models_results:\n",
    "    unnormalized_probs += edit_models_results[lang]\n",
    "print('Unnormalized probs tensor shape:', unnormalized_probs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Complete iteration:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataloader:\n",
    "    __edit_models_results = randomEditModel.forward_dynProg(*data[0])\n",
    "    __prior_lm_results = random_lm(data[0][0])\n",
    "    __results = __prior_lm_results\n",
    "    for lang in __edit_models_results:\n",
    "        __results += __edit_models_results[lang]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
