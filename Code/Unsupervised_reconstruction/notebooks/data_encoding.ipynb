{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, chdir\n",
    "\n",
    "if getcwd().endswith('notebooks'):\n",
    "    chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.getDataset import getCognatesSet, getIteration\n",
    "from data.vocab import computeInferenceData_Samples, computeInferenceData_Cognates, wordsToOneHots\n",
    "from random import randint\n",
    "\n",
    "raw_cognates = getCognatesSet()\n",
    "__random_start_index = randint(0, len(raw_cognates['french'])-6)\n",
    "cognates = computeInferenceData_Cognates({lang: wordsToOneHots(raw_cognates[lang]) for lang in raw_cognates})['french']\n",
    "cognates = (cognates[0][:, __random_start_index: __random_start_index + 5],\n",
    "            cognates[1][__random_start_index: __random_start_index + 5],\n",
    "            )\n",
    "__max_cognate_length = cognates[1].max().item()\n",
    "cognates = (cognates[0][:__max_cognate_length], cognates[1], __max_cognate_length)\n",
    "raw_cognates = raw_cognates['french'][__random_start_index: __random_start_index + 5]\n",
    "raw_samples = getIteration(1)[__random_start_index: __random_start_index + 5]\n",
    "samples = computeInferenceData_Samples(wordsToOneHots(raw_samples)) #TODO: simplify the data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS_TOKEN = \"(\" = 58\n",
      "EOS_TOKEN = \")\" = 57\n",
      "PADDING_TOKEN = \"-\" = 59\n"
     ]
    }
   ],
   "source": [
    "from data.vocab import vocabulary\n",
    "from models.types import SOS_TOKEN, EOS_TOKEN, PADDING_TOKEN\n",
    "print(f\"SOS_TOKEN = \\\"{SOS_TOKEN}\\\" = {vocabulary[SOS_TOKEN]}\")\n",
    "print(f\"EOS_TOKEN = \\\"{EOS_TOKEN}\\\" = {vocabulary[EOS_TOKEN]}\")\n",
    "print(f\"PADDING_TOKEN = \\\"{PADDING_TOKEN}\\\" = {vocabulary[PADDING_TOKEN]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples encoding: `InferenceData_Source` type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type refers to a tuple of three elements:\n",
    "- an IntTensor `S` of shape $\\left(\\max \\{|x|, x \\in \\textrm{batch}\\} + 2, c, b\\right)$. For all $0 \\leq i < c$ and $0 \\leq j < b$, `S[:, i, j]` represents one sample among the $b$ ones which are linked with the $i$-th cognate pair. It is represented along the first axis by tokens encoded with one-hot indexes and the sequence is opened by the `SOS_TOKEN` and the `EOS_TOKEN`.\n",
    "- a cpu ByteTensor `L` of shape $\\left( c, b \\right)$ containing the length of each samples with the boundaries token. It is defined such that `S[L[i, j]:, i, j]` is a list of the `PADDING_TOKEN`'s one-hot indices. Therefore, `L[i, j]` = $|x_{(i,j)}| + 2$, if we note $x_{(i,j)}$ as the raw sample (without the boundaries token) represented at the position (i, j) in `S`.\n",
    "- `n`: the max of `L` (if the tuple is correctly defined, then `n = S.size()[0]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pyblikaθjɔ', 'pɔlʊ', 'pldr', 'pulmɔ', 'plpa']\n",
      "tensor([[58, 13, 21,  1,  9,  6,  8,  0, 56,  7, 30, 57],\n",
      "        [58, 13, 30,  9, 43, 57, 59, 59, 59, 59, 59, 59],\n",
      "        [58, 13,  9,  2, 14, 57, 59, 59, 59, 59, 59, 59],\n",
      "        [58, 13, 17,  9, 10, 30, 57, 59, 59, 59, 59, 59],\n",
      "        [58, 13,  9, 13,  0, 57, 59, 59, 59, 59, 59, 59]], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "Sample tensor's shape: torch.Size([12, 5, 1])\n",
      "\n",
      "Samples' length (without boundaries): [10, 4, 4, 5, 4]\n",
      "Samples' length (with boundaries): tensor([12,  6,  6,  7,  6])\n",
      "Max sample length with boundaries: 12\n"
     ]
    }
   ],
   "source": [
    "print(raw_samples)\n",
    "print(samples[0][...,0].T)\n",
    "print(\"Sample tensor's shape:\", samples[0].size())\n",
    "print('\\n' + \"Samples' length (without boundaries):\", str([len(c) for c in raw_samples]))\n",
    "print(\"Samples' length (with boundaries):\", samples[1][:,0])\n",
    "print(\"Max sample length with boundaries:\", samples[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cognates encoding: `InferenceData_Targets` type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of data is defined by a tuple similar with `InferenceData_Source`, excepted that the `EOS_TOKEN` is here removed from the first IntTensor, which involves that the sequences lengths are reduced by one, compared to the sequences in the previous type. Therefore, we can sum up its three elements in the following list:\n",
    "- `S`: an IntTensor of shape $\\left( \\max \\{ |y_l|, y_l\\in \\textrm{batch}_l \\} + 1, c \\right)$\n",
    "- `L`: a cpu ByteTensor of shape $(c)$ `L[i]` = $|y_{l, i}| + 1$\n",
    "- `n`: the max of `L` (if the tuple is correctly defined, then `n = S.size()[0]` )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pyblikasjˈɔ̃', 'pˈɔ̃dʁ', 'pˈudʁ', 'pumˈɔ̃', 'pˈup']\n",
      "tensor([[58, 13, 21,  1,  9,  6,  8,  0, 15,  7, 51, 30, 54],\n",
      "        [58, 13, 51, 30, 54,  2, 41, 59, 59, 59, 59, 59, 59],\n",
      "        [58, 13, 51, 17,  2, 41, 59, 59, 59, 59, 59, 59, 59],\n",
      "        [58, 13, 17, 10, 51, 30, 54, 59, 59, 59, 59, 59, 59],\n",
      "        [58, 13, 51, 17, 13, 59, 59, 59, 59, 59, 59, 59, 59]], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "Cognate tensor's shape: torch.Size([13, 5])\n",
      "\n",
      "Cognates' length (without SOS token): [12, 6, 5, 6, 4]\n",
      "Cognates' length (with SOS token): tensor([13,  7,  6,  7,  5])\n",
      "Max cognate length with SOS token: 13\n"
     ]
    }
   ],
   "source": [
    "print(raw_cognates)\n",
    "print(cognates[0].T)\n",
    "print(\"Cognate tensor's shape:\",cognates[0].size())\n",
    "print('\\n' + \"Cognates' length (without SOS token):\", str([len(c) for c in raw_cognates]))\n",
    "print(\"Cognates' length (with SOS token):\", cognates[1])\n",
    "print(\"Max cognate length with SOS token:\", cognates[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "3.9.16"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "3.9.10"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
