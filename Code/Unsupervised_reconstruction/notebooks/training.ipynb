{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximisation-expectation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, chdir\n",
    "\n",
    "# set the current working directory to the repository's root, if required\n",
    "if getcwd().endswith('notebooks'):\n",
    "    chdir('./../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install tabulate\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.4f}')\n",
    "\n",
    "def display_horizontaly_two_tables(df:pd.DataFrame,df2:pd.DataFrame, title1:str, title2:str):\n",
    "    df_md = df.to_markdown().split('\\n')\n",
    "    df2_md = df2.to_markdown().split('\\n')\n",
    "    title_line = title1 + \" \" * (len(df_md[0])-len(title1)) + \"\\t\" + title2\n",
    "    two_tabs = \"\\n\".join([title_line] + [df_md[i] + '\\t' + df2_md[i] for i in range(len(df_md))])\n",
    "    print(two_tabs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|y| max = 18\n",
      "|x| max = 16\n"
     ]
    }
   ],
   "source": [
    "from data.getDataset import getCognatesSet, getIteration\n",
    "from data.vocab import computeInferenceData, V_SIZE\n",
    "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence\n",
    "from Source.editModel import EditModel\n",
    "\n",
    "cognates = computeInferenceData(pad_sequence(getCognatesSet()['french'], batch_first=True))\n",
    "currentReconstructions = computeInferenceData(pad_sequence(getIteration(1), batch_first=True))\n",
    "\n",
    "randomEditModel = EditModel(cognates, 'french', 50)\n",
    "x_maxLength = pad_packed_sequence(currentReconstructions[0])[0].size()[0] - 2\n",
    "y_maxLength = pad_packed_sequence(cognates[0])[0].size()[0] - 2\n",
    "print('|y| max =', y_maxLength)\n",
    "print('|x| max =', x_maxLength)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward dynamic Program"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference in edit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomEditModel.update_cachedTargetContext()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward dynamic Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Source.dynamicPrograms import compute_posteriors\n",
    "\n",
    "randomEditModel.update_cachedTargetContext()\n",
    "targets_prob = compute_posteriors(randomEditModel, currentReconstructions, cognates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on $x :=$`\"absyrdʊ\"` and $y :=$`\"absˈyʁd\"` ($|x|=7$ and $|y|=7$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "from numpy import array\n",
    "idx = 20 # the index in the batch of the sample to be studied\n",
    "x_length, y_length = 7, 7\n",
    "dlt = tensor(array([[randomEditModel.dlt(i, j)[idx] for j in range(20)] for i in range(18)]))\n",
    "end = tensor(array([[randomEditModel.end(i, j)[idx] for j in range(20)] for i in range(18)]))\n",
    "sub = tensor(array([[randomEditModel.sub(i, j)[idx] for j in range(20)] for i in range(18)]))\n",
    "ins = tensor(array([[randomEditModel.ins(i, j)[idx] for j in range(20)] for i in range(18)]))\n",
    "\n",
    "backward_prob_dlt = targets_prob.dlt[:,:,idx]\n",
    "backward_prob_end = targets_prob.end[:,:,idx]\n",
    "backward_prob_sub = targets_prob.sub[:,:,idx]\n",
    "backward_prob_ins = targets_prob.ins[:,:,idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display of cached probabilities for the substitution and the deletion operations\n",
    "\n",
    "Notice that the logarithmic probabilities that have not to be defined for these operations are automatically set to $-\\infty{}$ thanks to the recurrence mathematical relations of the backward dynamic program. So do the undefined probabilities in padding positions, thanks to the neutrality of edit model's cached inference probabilities (which equal $0$ in the log space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsitution Operation                                                                                \tDeletion Operation\n",
      "|    |        0 |        1 |        2 |        3 |        4 |        5 |        6 |      7 |      8 |\t|    |        0 |        1 |        2 |        3 |        4 |        5 |        6 |         7 |      8 |\n",
      "|---:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|-------:|-------:|\t|---:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|----------:|-------:|\n",
      "|  0 | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -2e+09 | -2e+09 |\t|  0 | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09    | -2e+09 |\n",
      "|  1 | -1.29095 | -1.98294 | -2.76997 | -3.711   | -4.83866 | -6.27045 | -8.27874 | -1e+09 | -1e+09 |\t|  1 | -1.50347 | -2.00356 | -2.61257 | -3.31295 | -4.15105 | -5.17892 | -6.46528 | -8.32801  | -1e+09 |\n",
      "|  2 | -2.01502 | -1.88899 | -2.16685 | -2.7007  | -3.47856 | -4.58699 | -6.2791  | -1e+09 | -1e+09 |\t|  2 | -2.41869 | -2.10369 | -2.20287 | -2.49743 | -2.98513 | -3.68834 | -4.661   | -6.20333  | -1e+09 |\n",
      "|  3 | -2.84982 | -2.19903 | -2.07155 | -2.2497  | -2.70105 | -3.49284 | -4.8607  | -1e+09 | -1e+09 |\t|  3 | -3.46787 | -2.63116 | -2.32434 | -2.26452 | -2.42494 | -2.80988 | -3.46022 | -4.65701  | -1e+09 |\n",
      "|  4 | -3.81016 | -2.75039 | -2.27308 | -2.12312 | -2.25631 | -2.72489 | -3.74499 | -1e+09 | -1e+09 |\t|  4 | -4.70624 | -3.46367 | -2.80625 | -2.4196  | -2.26074 | -2.32019 | -2.62335 | -3.42512  | -1e+09 |\n",
      "|  5 | -4.94388 | -3.53001 | -2.72941 | -2.25976 | -2.06596 | -2.18371 | -2.80038 | -1e+09 | -1e+09 |\t|  5 | -6.25969 | -4.66638 | -3.68537 | -2.98075 | -2.49436 | -2.20108 | -2.10058 | -2.39635  | -1e+09 |\n",
      "|  6 | -6.38717 | -4.64343 | -3.52665 | -2.73019 | -2.18382 | -1.89793 | -2.0062  | -1e+09 | -1e+09 |\t|  6 | -8.38249 | -6.46286 | -5.16535 | -4.13573 | -3.29573 | -2.59529 | -1.97641 | -1.49892  | -1e+09 |\n",
      "|  7 | -8.38249 | -6.32034 | -4.88268 | -3.73707 | -2.78596 | -1.98456 | -1.27955 | -1e+09 | -1e+09 |\t|  7 | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -0.714784 | -1e+09 |\n",
      "|  8 | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09 | -1e+09 |\t|  8 | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09    | -1e+09 |\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(backward_prob_sub[:x_length+2, :y_length+2])\n",
    "df2 = pd.DataFrame(backward_prob_dlt[:x_length+2, :y_length+2])\n",
    "\n",
    "display_horizontaly_two_tables(df, df2, \"Subsitution Operation\", \"Deletion Operation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering of the target and the logits before the loss computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderedTargets, renderedLogits = randomEditModel.renderTargetAndLogitsBeforeLossComputation(currentReconstructions, targets_prob)\n",
    "renderedTargets = renderedTargets[:,:,idx].cpu().numpy()\n",
    "renderedLogits = renderedLogits[:,:,idx].cpu().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of the rendered target probs format and the cached probs format\n",
    "\n",
    "A reduction of the renderedTargets has been done for the displaying. The comparison is done for the insertion and the ending operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion operation - cached posterior probs                                                          \tEnding operation - cached posterior probs\n",
      "|    |         0 |        1 |        2 |        3 |        4 |        5 |        6 |      7 |      8 |\t|    |         0 |        1 |        2 |        3 |        4 |        5 |        6 |         7 |      8 |\n",
      "|---:|----------:|---------:|---------:|---------:|---------:|---------:|---------:|-------:|-------:|\t|---:|----------:|---------:|---------:|---------:|---------:|---------:|---------:|----------:|-------:|\n",
      "|  0 | -0.687895 | -1.46918 | -2.36335 | -3.40391 | -4.64833 | -6.18891 | -8.32801 | -1e+09 | -1e+09 |\t|  0 | -0.698427 | -1.30005 | -1.99503 | -2.79915 | -3.74374 | -4.88946 | -6.3142  | -8.32801  | -1e+09 |\n",
      "|  1 | -1e+09    | -1.99044 | -2.09865 | -2.62776 | -3.47194 | -4.66584 | -6.48434 | -1e+09 | -1e+09 |\t|  1 | -1e+09    | -1.97779 | -1.886   | -2.17996 | -2.72362 | -3.52123 | -4.62787 | -6.33057  | -1e+09 |\n",
      "|  2 | -1e+09    | -2.6253  | -2.20465 | -2.3247  | -2.81532 | -3.68391 | -5.18552 | -1e+09 | -1e+09 |\t|  2 | -1e+09    | -2.79852 | -2.17724 | -2.06346 | -2.25298 | -2.72398 | -3.51624 | -4.89658  | -1e+09 |\n",
      "|  3 | -1e+09    | -3.36297 | -2.52618 | -2.29046 | -2.45195 | -3.00249 | -4.17955 | -1e+09 | -1e+09 |\t|  3 | -1e+09    | -3.76262 | -2.72452 | -2.25632 | -2.1159  | -2.26725 | -2.73688 | -3.77007  | -1e+09 |\n",
      "|  4 | -1e+09    | -4.21662 | -3.02131 | -2.45855 | -2.30016 | -2.52663 | -3.35616 | -1e+09 | -1e+09 |\t|  4 | -1e+09    | -4.90678 | -3.50942 | -2.71548 | -2.25405 | -2.07903 | -2.20172 | -2.83865  | -1e+09 |\n",
      "|  5 | -1e+09    | -5.23099 | -3.70394 | -2.82277 | -2.33599 | -2.21099 | -2.63756 | -1e+09 | -1e+09 |\t|  5 | -1e+09    | -6.33192 | -4.60252 | -3.49189 | -2.70154 | -2.17315 | -1.8926  | -2.02252  | -1e+09 |\n",
      "|  6 | -1e+09    | -6.54035 | -4.68823 | -3.48111 | -2.64013 | -2.11076 | -2.02931 | -1e+09 | -1e+09 |\t|  6 | -1e+09    | -8.33897 | -6.28417 | -4.84942 | -3.70384 | -2.76753 | -1.969   | -1.32454  | -1e+09 |\n",
      "|  7 | -1e+09    | -8.38249 | -6.20062 | -4.64549 | -3.39834 | -2.35284 | -1.45869 | -1e+09 | -1e+09 |\t|  7 | -2e+09    | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -0.671968 | -1e+09 |\n",
      "|  8 | -2e+09    | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09 | -1e+09 |\t|  8 | -2e+09    | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09    | -1e+09 |\n",
      "Insertion operation - rendered target probs                                                     \tEnding operation - rendered target probs\n",
      "|    |         0 |        1 |        2 |        3 |        4 |        5 |        6 |   7 |   8 |\t|    |         0 |        1 |        2 |        3 |        4 |        5 |        6 |         7 |   8 |\n",
      "|---:|----------:|---------:|---------:|---------:|---------:|---------:|---------:|----:|----:|\t|---:|----------:|---------:|---------:|---------:|---------:|---------:|---------:|----------:|----:|\n",
      "|  0 | -0.687895 | -1.46918 | -2.36335 | -3.40391 | -4.64833 | -6.18891 | -8.32801 |   0 |   0 |\t|  0 | -0.698427 | -1.30005 | -1.99503 | -2.79915 | -3.74374 | -4.88946 | -6.3142  | -8.32801  |  -0 |\n",
      "|  1 | -1e+09    | -1.99044 | -2.09865 | -2.62776 | -3.47194 | -4.66584 | -6.48434 |   0 |   0 |\t|  1 | -1e+09    | -1.97779 | -1.886   | -2.17996 | -2.72362 | -3.52123 | -4.62787 | -6.33057  |  -0 |\n",
      "|  2 | -1e+09    | -2.6253  | -2.20465 | -2.3247  | -2.81532 | -3.68391 | -5.18552 |   0 |   0 |\t|  2 | -1e+09    | -2.79852 | -2.17724 | -2.06346 | -2.25298 | -2.72398 | -3.51624 | -4.89658  |  -0 |\n",
      "|  3 | -1e+09    | -3.36297 | -2.52618 | -2.29046 | -2.45195 | -3.00249 | -4.17955 |   0 |   0 |\t|  3 | -1e+09    | -3.76262 | -2.72452 | -2.25632 | -2.1159  | -2.26725 | -2.73688 | -3.77007  |  -0 |\n",
      "|  4 | -1e+09    | -4.21662 | -3.02131 | -2.45855 | -2.30016 | -2.52663 | -3.35616 |   0 |   0 |\t|  4 | -1e+09    | -4.90678 | -3.50942 | -2.71548 | -2.25405 | -2.07903 | -2.20172 | -2.83865  |  -0 |\n",
      "|  5 | -1e+09    | -5.23099 | -3.70394 | -2.82277 | -2.33599 | -2.21099 | -2.63756 |   0 |   0 |\t|  5 | -1e+09    | -6.33192 | -4.60252 | -3.49189 | -2.70154 | -2.17315 | -1.8926  | -2.02252  |  -0 |\n",
      "|  6 | -1e+09    | -6.54035 | -4.68823 | -3.48111 | -2.64013 | -2.11076 | -2.02931 |   0 |   0 |\t|  6 | -1e+09    | -8.33897 | -6.28417 | -4.84942 | -3.70384 | -2.76753 | -1.969   | -1.32454  |  -0 |\n",
      "|  7 | -1e+09    | -8.38249 | -6.20062 | -4.64549 | -3.39834 | -2.35284 | -1.45869 |   0 |   0 |\t|  7 | -2e+09    | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -1e+09   | -0.671968 |  -0 |\n",
      "|  8 |  0        |  0       |  0       |  0       |  0       |  0       |  0       |   0 |   0 |\t|  8 | -0        | -0       | -0       | -0       | -0       | -0       | -0       | -0        |  -0 |\n",
      "Insertion operation - rendered logits                                                          \tEnding operation - rendered logits\n",
      "|    |        0 |        1 |        2 |        3 |        4 |        5 |        6 |   7 |   8 |\t|    |        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |   8 |\n",
      "|---:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|----:|----:|\t|---:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|----:|\n",
      "|  0 | -4.08401 | -4.05489 | -4.03671 | -4.11678 | -4.15693 | -4.17482 | -3.97175 |   0 |   0 |\t|  0 | -4.03194 | -4.02446 | -4.00637 | -4.00552 | -3.99747 | -4.00824 | -4.0149  | -4.00609 |  -0 |\n",
      "|  1 | -4.06347 | -4.0586  | -4.0478  | -4.0958  | -4.16639 | -4.17679 | -4.00117 |   0 |   0 |\t|  1 | -4.03323 | -4.02575 | -4.00766 | -4.00679 | -3.99875 | -4.00951 | -4.01618 | -4.00737 |  -0 |\n",
      "|  2 | -4.08926 | -4.06279 | -4.03245 | -4.11684 | -4.17238 | -4.20064 | -4.00945 |   0 |   0 |\t|  2 | -4.02889 | -4.02136 | -4.00327 | -4.00241 | -3.99439 | -4.00514 | -4.01183 | -4.003   |  -0 |\n",
      "|  3 | -4.08027 | -4.04686 | -4.06137 | -4.113   | -4.15443 | -4.18198 | -4.00991 |   0 |   0 |\t|  3 | -4.02802 | -4.02051 | -4.00241 | -4.00156 | -3.99351 | -4.00428 | -4.01096 | -4.00212 |  -0 |\n",
      "|  4 | -4.09864 | -4.067   | -4.06733 | -4.09071 | -4.1679  | -4.19753 | -4.01153 |   0 |   0 |\t|  4 | -4.03712 | -4.02962 | -4.01151 | -4.01066 | -4.0026  | -4.01339 | -4.02009 | -4.01124 |  -0 |\n",
      "|  5 | -4.10173 | -4.03421 | -4.06476 | -4.09501 | -4.17203 | -4.18893 | -4.02636 |   0 |   0 |\t|  5 | -4.02081 | -4.01329 | -3.99518 | -3.99434 | -3.9863  | -3.99708 | -4.00374 | -3.99489 |  -0 |\n",
      "|  6 | -4.11437 | -4.05802 | -4.04662 | -4.1099  | -4.18759 | -4.19709 | -4.01879 |   0 |   0 |\t|  6 | -4.03303 | -4.02551 | -4.00741 | -4.00656 | -3.9985  | -4.00927 | -4.01595 | -4.00706 |  -0 |\n",
      "|  7 | -4.11301 | -4.07353 | -4.03821 | -4.10445 | -4.16592 | -4.22768 | -4.04017 |   0 |   0 |\t|  7 | -4.01862 | -4.01109 | -3.99301 | -3.9921  | -3.98405 | -3.99483 | -4.00154 | -3.99266 |  -0 |\n",
      "|  8 |  0       |  0       |  0       |  0       |  0       |  0       |  0       |   0 |   0 |\t|  8 | -0       | -0       | -0       | -0       | -0       | -0       | -0       | -0       |  -0 |\n"
     ]
    }
   ],
   "source": [
    "df_insBackward = pd.DataFrame(backward_prob_ins[:x_length+2, :y_length+2])\n",
    "df_endBackward = pd.DataFrame(backward_prob_end[:x_length+2, :y_length+2])\n",
    "df_insRenderedTargets = pd.DataFrame(renderedTargets[:x_length+2, :y_length+2, -V_SIZE-1:-1].sum(axis=2))\n",
    "df_endRenderedTargets = pd.DataFrame(renderedTargets[:x_length+2, :y_length+2, -1])\n",
    "df_insRenderedLogits = pd.DataFrame(renderedLogits[:x_length+2, :y_length+2, -V_SIZE-1:-1].sum(axis=2))\n",
    "df_endRenderedLogits = pd.DataFrame(renderedLogits[:x_length+2, :y_length+2, -1])\n",
    "\n",
    "display_horizontaly_two_tables(df_insBackward, df_endBackward, \"Insertion operation - cached posterior probs\", \"Ending operation - cached posterior probs\")\n",
    "display_horizontaly_two_tables(df_insRenderedTargets, df_endRenderedTargets, \"Insertion operation - rendered target probs\", \"Ending operation - rendered target probs\")\n",
    "display_horizontaly_two_tables(df_insRenderedLogits, df_endRenderedLogits, \"Insertion operation - rendered logits\", \"Ending operation - rendered logits\")\n",
    "\n",
    "# display(pd.merge(df_insBackward, df_endBackward, left_index=True, right_index=True, suffixes=(' ins', ' end')),\n",
    "#         pd.merge(df_insRenderedTargets, df_endRenderedTargets, left_index=True, right_index=True, suffixes=(' ins', ' end'))\n",
    "#         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 (PyTorch)",
   "language": "python",
   "name": "notebook_torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
