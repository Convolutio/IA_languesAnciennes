{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, chdir\n",
    "\n",
    "if getcwd().endswith('notebooks'):\n",
    "    chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.getDataset import getCognatesSet, getIteration\n",
    "from data.vocab import computeInferenceData_Source, computeInferenceData_Target, wordsToOneHots\n",
    "from random import randint\n",
    "\n",
    "raw_cognates = getCognatesSet()['french']\n",
    "__random_start_index = randint(0, len(raw_cognates)-6)\n",
    "raw_cognates = raw_cognates[__random_start_index: __random_start_index + 5]\n",
    "cognates = computeInferenceData_Target(wordsToOneHots(raw_cognates))\n",
    "raw_samples = getIteration(1)[__random_start_index: __random_start_index + 5]\n",
    "samples = computeInferenceData_Source(wordsToOneHots(raw_samples)) #TODO: simplify the data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples encoding: `InferenceData_Source` type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type refers to a tuple of three elements:\n",
    "- an IntTensor `S` of shape $\\left(\\max \\{|x|, x \\in \\textrm{batch}\\} + 2, c, b\\right)$. For all $0 \\leq i < c$ and $0 \\leq j < b$, `S[:, i, j]` represents one sample among the $b$ ones which are linked with the $i$-th cognate pair. It is represented along the first axis by tokens encoded with one-hot indexes and the sequence is opened by the `SOS_TOKEN` and the `EOS_TOKEN`.\n",
    "- a cpu ByteTensor `L` of shape $\\left( c, b \\right)$ containing the length of each samples with the boundaries token. It is defined such that `S[L[i, j]:, i, j]` is a list of the `PADDING_TOKEN`'s one-hot indices. Therefore, `L[i, j]` = $|x_{(i,j)}| + 2$, if we note $x_{(i,j)}$ as the raw sample (without the boundaries token) represented at the position (i, j) in `S`.\n",
    "- `n`: the max of `L` (if the tuple is correctly defined, then `n = S.size()[0]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ɔrixinal', 'ɔrnamɛntʊ', 'uʁor', 'ɔrlɔʒ', 'ɔrtoðoksa']\n",
      "tensor([[58, 30, 14,  6, 20,  6, 11,  0,  9, 57, 59],\n",
      "        [58, 30, 14, 11,  0, 10, 32, 11, 16, 43, 57],\n",
      "        [58, 17, 41, 12, 14, 57, 59, 59, 59, 59, 59],\n",
      "        [58, 30, 14,  9, 30, 46, 57, 59, 59, 59, 59],\n",
      "        [58, 30, 14, 16, 12, 23, 12,  8, 15,  0, 57]], dtype=torch.int32)\n",
      "torch.Size([11, 5, 1])\n",
      "\n",
      "Samples' length (without boundaries): [8, 9, 4, 5, 9]\n",
      "Samples' length (with boundaries): tensor([10, 11,  6,  7, 11])\n",
      "Max sample length with boundaries: 11\n"
     ]
    }
   ],
   "source": [
    "print(raw_samples)\n",
    "print(samples[0][...,0].T)\n",
    "print(samples[0].size())\n",
    "print('\\n' + \"Samples' length (without boundaries):\", str([len(c) for c in raw_samples]))\n",
    "print(\"Samples' length (with boundaries):\", samples[1][:,0])\n",
    "print(\"Max sample length with boundaries:\", samples[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cognates encoding: `InferenceData_Targets` type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of data is defined by a tuple similar with `InferenceData_Source`, excepted that the `EOS_TOKEN` is here removed from the first IntTensor, which involves that the sequences lengths are reduced by one, compared to the sequences in the previous type. Therefore, we can sum up its three elements in the following list:\n",
    "- `S`: an IntTensor of shape $\\left( \\max \\{ |y_l|, y_l\\in \\textrm{batch}_l \\} + 1, c \\right)$\n",
    "- `L`: a cpu ByteTensor of shape $(c)$ `L[i]` = $|y_{l, i}| + 1$\n",
    "- `n`: the max of `L` (if the tuple is correctly defined, then `n = S.size()[0]` )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oʁiʒinˈal', 'ɔʁnəmˈɑ̃', 'oʁˈœʁ', 'ɔʁlˈɔʒ', 'ɔʁtodoksˈi']\n",
      "tensor([[58, 12, 41,  6, 46,  6, 11, 51,  0,  9, 59],\n",
      "        [58, 30, 41, 11, 31, 10, 51, 28, 54, 59, 59],\n",
      "        [58, 12, 41, 51, 26, 41, 59, 59, 59, 59, 59],\n",
      "        [58, 30, 41,  9, 51, 30, 46, 59, 59, 59, 59],\n",
      "        [58, 30, 41, 16, 12,  2, 12,  8, 15, 51,  6]], dtype=torch.int32)\n",
      "torch.Size([11, 5])\n",
      "\n",
      "Cognates' length (without SOS token): [9, 8, 5, 6, 10]\n",
      "Cognates' length (with SOS token): tensor([10,  9,  6,  7, 11])\n",
      "Max cognate length with SOS token: 11\n"
     ]
    }
   ],
   "source": [
    "print(raw_cognates)\n",
    "print(cognates[0].T)\n",
    "print(cognates[0].size())\n",
    "print('\\n' + \"Cognates' length (without SOS token):\", str([len(c) for c in raw_cognates]))\n",
    "print(\"Cognates' length (with SOS token):\", cognates[1])\n",
    "print(\"Max cognate length with SOS token:\", cognates[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
