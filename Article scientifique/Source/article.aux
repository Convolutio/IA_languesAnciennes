\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `:\active 
\catcode `;\active 
\catcode `!\active 
\catcode `?\active 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\babel@aux{french}{}
\babel@aux{french}{}
\citation{campbell}
\citation{bouchard}
\citation{bouchard}
\citation{andre}
\citation{meloni}
\citation{andre}
\citation{bouchard}
\citation{meloni}
\citation{fourier}
\citation{andre}
\citation{meloni}
\citation{andre}
\@writefile{toc}{\contentsline {section}{\numberline {1}Observation}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}La reconstruction de la proto-langue et son automatisation}{2}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}L'intérêt de la démarche non-supervisée pour un problème à faibles ressources}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}L'état de l'art de la démarche neuronale dans la prédiction de proto-formes}{2}{subsection.1.3}\protected@file@percent }
\citation{andre}
\citation{jurafsky_ngram}
\citation{meloni}
\citation{andre}
\citation{bouchard}
\citation{meloni}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problématique}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Hypothèses}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Expérience}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Comparaison des distances d'édition}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Mise en place du modèle de reconstruction}{3}{subsection.4.2}\protected@file@percent }
\citation{andre}
\citation{meloni}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Courbes possibles d'évolution du degré de pertinence des modèles de reconstruction en fonction de la quantité de données fournies au modèle de langue, si les hypothèses variationnelles énoncées plus tôt sont validées. En échelonnant cette grandeur de 0 à 1, on définit une pertinence minimale en-dessous de laquelle le modèle n'est certainement pas exploitable. Les valeurs atteintes pour $a_i$ et $b_i$ sont attendues d'être différentes pour des architectures différentes.\relax }}{4}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:fighyp}{{1}{4}{Courbes possibles d'évolution du degré de pertinence des modèles de reconstruction en fonction de la quantité de données fournies au modèle de langue, si les hypothèses variationnelles énoncées plus tôt sont validées. En échelonnant cette grandeur de 0 à 1, on définit une pertinence minimale en-dessous de laquelle le modèle n'est certainement pas exploitable. Les valeurs atteintes pour $a_i$ et $b_i$ sont attendues d'être différentes pour des architectures différentes.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Modèles de langue}{4}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Base de données}{4}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Implémentation des modèles et leur entraînement}{4}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Résultats}{5}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Interprétation}{5}{section.6}\protected@file@percent }
\citation{bouchard_austro}
\citation{greenville}
\citation{andre}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Histogramme fictif} : Distance d'édition suivant le type de modèle et la quantité de mots latins phonétisés fournie. Résultat représentant le cas n°4 : la distance d'édition diminue au fil de la quantités de mots augmentent, quel que soit l'architecture. Cependant plus l'architecture se complexifie, plus la distance d'édition augmente.\relax }}{6}{figure.caption.3}\protected@file@percent }
\newlabel{fig:figres}{{2}{6}{\textbf {Histogramme fictif} : Distance d'édition suivant le type de modèle et la quantité de mots latins phonétisés fournie. Résultat représentant le cas n°4 : la distance d'édition diminue au fil de la quantités de mots augmentent, quel que soit l'architecture. Cependant plus l'architecture se complexifie, plus la distance d'édition augmente.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion et Limitations}{6}{section.7}\protected@file@percent }
\bibdata{biblio}
\bibcite{bouchard_austro}{{1}{2013}{{Alexandre Bouchard-Côté and Klein}}{{}}}
\bibcite{bouchard}{{2}{2009}{{Bouchard-C\^{o}t\'{e} et~al.}}{{Bouchard-C\^{o}t\'{e}, Griffiths, and Klein}}}
\bibcite{campbell}{{3}{2004}{{Campbell}}{{}}}
\bibcite{fourier}{{4}{2022}{{Fourrier}}{{}}}
\bibcite{andre}{{5}{2022}{{He et~al.}}{{He, Tomlin, and Klein}}}
\bibcite{jurafsky_ngram}{{6}{}{{Jurafsky and Martin}}{{}}}
\bibcite{meloni}{{7}{2021}{{Meloni et~al.}}{{Meloni, Ravfogel, and Goldberg}}}
\bibcite{greenville}{{8}{2008}{{Simon J.~Greenhill}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Configurations et hyperparamètres pour le modèle de langue RNN}{8}{appendix.A}\protected@file@percent }
\gdef \@abspage@last{8}
